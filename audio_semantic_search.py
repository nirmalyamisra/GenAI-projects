# -*- coding: utf-8 -*-
"""Audio_semantic_search.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GPeCvl3BBx1fuWp8E4cx8eznR2PfATWq
"""

!pip install openai-whisper
!pip install chromadb
!pip install sentence-transformers
!pip install torch ffmpeg-python

import os
import zipfile
import whisper
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings

# --- Step 1: Extract .wav files from ZIP ---
zip_path = "kaggle_audio_call_center_dataset.zip"
extract_dir = "./extracted_audio"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

# Filter only .wav files
wav_files = [os.path.join(extract_dir, f) for f in os.listdir(extract_dir) if f.endswith(".wav")]

# --- Step 2: Initialize models ---
whisper_model = whisper.load_model("base")
embedder = SentenceTransformer("all-MiniLM-L6-v2")
client = chromadb.PersistentClient(path="./chroma_db")
collection = client.get_or_create_collection(name="audio_chunks")

# --- Step 3: Process each .wav file ---
for audio_path in wav_files:
    print(f"üîç Transcribing: {audio_path}")
    result = whisper_model.transcribe(audio_path)
    segments = result["segments"]

    chunks = []
    metadatas = []

    for i, segment in enumerate(segments):
        chunk_text = segment["text"].strip()
        start = segment["start"]
        end = segment["end"]
        chunks.append(chunk_text)
        metadatas.append({
            "chunk_id": i,
            "start": start,
            "end": end,
            "source": audio_path
        })

    # --- Step 4: Embed and store ---
    embeddings = embedder.encode(chunks).tolist()

    for i, (text, embedding, metadata) in enumerate(zip(chunks, embeddings, metadatas)):
        collection.add(
            documents=[text],
            embeddings=[embedding],
            metadatas=[metadata],
            ids=[f"{os.path.basename(audio_path)}_{i}"]
        )

print("‚úÖ All audio files processed and stored in ChromaDB.")

import requests
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings # Import Settings

# üîë Gemini API setup
API_KEY = "AIzaSyAxDQzSGkdljIGX0bBeY2MoLtcB8VLKerA"
ENDPOINT = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent"

# üß† Step 1: Encode query
query = "which products have defect?"
embedder = SentenceTransformer("all-MiniLM-L6-v2")
query_embedding = embedder.encode([query]).tolist()[0]

# üìö Step 2: Search ChromaDB for matching documents
# Use PersistentClient to connect to the existing database
chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_collection(name="audio_chunks")

results = collection.query(query_embeddings=[query_embedding], n_results=3)

# üß© Step 3: Filter and format matched chunks
threshold = 2.3
matched_chunks = []

for doc, metadata, distance in zip(
    results["documents"][0],
    results["metadatas"][0],
    results["distances"][0]
):
    if distance < threshold:
        chunk = f"[{metadata['start']} - {metadata['end']}]: {doc} (Distance: {distance:.4f})"
        matched_chunks.append(chunk)

if not matched_chunks:
    print("üö´ No relevant match found.")
    exit()

context_text = "\n\n".join(matched_chunks)

# üí¨ Step 4: Build the Gemini Prompt
prompt_text = f"""
You are a smart assistant helping analyze customer issues related to the query: "{query}".

Here are the top matching excerpts from the database based on semantic similarity:

{context_text}

Based on these chunks, summarize the key issues customers are facing and suggest possible trends or concerns.
"""

prompt = {
    "contents": [
        {
            "parts": [
                {"text": prompt_text}
            ]
        }
    ]
}

# üöÄ Step 5: Send request to Gemini API
response = requests.post(
    f"{ENDPOINT}?key={API_KEY}",
    headers={"Content-Type": "application/json"},
    json=prompt
)

# üì¢ Step 6: Show result
if response.status_code == 200:
    result = response.json()
    text = result["candidates"][0]["content"]["parts"][0]["text"]
    print("üß† Gemini Response:\n", text)
else:
    print(f"‚ùå Error {response.status_code}: {response.text}")